{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YjdNfZhO4Trt"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nk2000/AI-Sapienza/blob/master/Copy_of_Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnoE-Qa6q7BO",
        "colab_type": "code",
        "outputId": "66f1eaaf-a102-4834-da6f-c538909a19b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "import os\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/DM-HW4\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8jFULzI_leV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def load_glove(path=None, dim=None, size=None):   # download from https://nlp.stanford.edu/projects/glove/\n",
        "    if path is None:\n",
        "        if size=='6B':\n",
        "            path = data_dir + 'glove.6B/glove.6B.' + str(dim) + 'd.txt'\n",
        "        elif size=='42B' and dim==300:\n",
        "            path = data_dir+'glove.42B.300d.txt'\n",
        "        elif size=='840B' and dim==300:\n",
        "            path = data_dir+'glove.840B.300d.txt'\n",
        "        else:\n",
        "            print(u'No pre-trained word-embeddings at dir:%s' % (data_dir))\n",
        "            exit(-3)\n",
        "\n",
        "    wordvecs = {}\n",
        "    with open(path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "            tokens = line.split(' ')\n",
        "            vec = np.array(tokens[1:], dtype=np.float32)\n",
        "            wordvecs[tokens[0]] = vec\n",
        "\n",
        "    return wordvecs\n",
        "\n",
        "\n",
        "def fill_with_gloves(word_to_id, path=None, emb_size=None, vocab_size=None, wordvecs=None):\n",
        "    if not wordvecs:\n",
        "        wordvecs = load_glove(path, emb_size, vocab_size)\n",
        "\n",
        "    n_words = len(word_to_id)\n",
        "\n",
        "    if emb_size is None:\n",
        "        emb_size = len(wordvecs[list(wordvecs.keys())[0]])\n",
        "\n",
        "    res = np.zeros([n_words, emb_size], dtype=np.float32)\n",
        "    n_not_found = 0\n",
        "    words_notin = set()\n",
        "    for word, id in word_to_id.items():\n",
        "        if '#' in word:\n",
        "            word = word.split('#')[0]   # Remove pos tag\n",
        "        \n",
        "        # maybe trained embedding containes n-gram embeddding\n",
        "        if word in wordvecs:\n",
        "            words = [word]\n",
        "        elif '-' in word:\n",
        "            words = word.split('-')\n",
        "        elif '_' in word:\n",
        "            words = word.split('_')\n",
        "        else:\n",
        "            words = [word]\n",
        "\n",
        "        vecs = []\n",
        "        for w in words:\n",
        "            if w in wordvecs:\n",
        "                vecs.append(wordvecs[w])    # add word2vec for multi-word\n",
        "                \n",
        "        if vecs != []:\n",
        "            res[id, :] = np.mean(np.array(vecs), 0)\n",
        "        else:\n",
        "            words_notin.add(word)\n",
        "            n_not_found += 1\n",
        "            res[id, :] = np.random.normal(0.0, 0.1, emb_size)\n",
        "    print( 'n words not found in glove word vectors: ' + str(n_not_found))\n",
        "#    if words_notin:\n",
        "#        open('../tmp/word_not_in_glove.txt','w').write((u'\\n'.join(words_notin)).encode('utf-8'))\n",
        "\n",
        "    return res\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQzfwshQ4Pii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn import metrics\n",
        "\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import sys\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjdNfZhO4Trt",
        "colab_type": "text"
      },
      "source": [
        "# Explore the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEAsX5b74Sy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\"lyrics.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzP2JH5M4p16",
        "colab_type": "code",
        "outputId": "bc9e5a97-da0b-4980-8c79-95a5c1925b40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ego-remix</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>then-tell-me</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>honesty</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>you-are-my-rock</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>black-culture</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Party the people, the people the party it's po...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ...                                             lyrics\n",
              "0      0  ...  Oh baby, how you doing?\\nYou know I'm gonna cu...\n",
              "1      1  ...  playin' everything so easy,\\nit's like you see...\n",
              "2      2  ...  If you search\\nFor tenderness\\nIt isn't hard t...\n",
              "3      3  ...  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...\n",
              "4      4  ...  Party the people, the people the party it's po...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc2k9qqZVwoo",
        "colab_type": "text"
      },
      "source": [
        "## Artist can be useful feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA6LC9qbVXj8",
        "colab_type": "code",
        "outputId": "0abe845a-128f-46e0-f94d-7234d015980a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "artist = data['artist'].value_counts()\n",
        "print(\"length of artists\", len(artist))\n",
        "artist[:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of artists 18231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dolly-parton        755\n",
              "american-idol       700\n",
              "elton-john          680\n",
              "b-b-king            667\n",
              "chris-brown         655\n",
              "eddy-arnold         628\n",
              "barbra-streisand    624\n",
              "ella-fitzgerald     623\n",
              "bob-dylan           614\n",
              "bee-gees            599\n",
              "Name: artist, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usw9Kh01WUrL",
        "colab_type": "text"
      },
      "source": [
        "## Deal with NaN rows\n",
        "\n",
        "I notice that there exists Nan in lyrics. I want to do following steps\n",
        "\n",
        "\n",
        "1.   Statistics\n",
        "2.   Delete Nan row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiWUmPONUGWk",
        "colab_type": "code",
        "outputId": "000b9a4a-e9ca-4c67-9c81-4ad83e31651b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "count_nan = len(data) - data.count()\n",
        "print(count_nan)\n",
        "print('----------------------------------')\n",
        "print(\"Nan lyrics ratio {}\".format(count_nan['lyrics']/len(data)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "index         0\n",
            "song          2\n",
            "year          0\n",
            "artist        0\n",
            "genre         0\n",
            "lyrics    95680\n",
            "dtype: int64\n",
            "----------------------------------\n",
            "Nan lyrics ratio 0.264136463144295\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okeuzk00UTZ-",
        "colab_type": "code",
        "outputId": "72593b09-48d4-4794-ca25-8e631429635e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Step 2 Delete Nan row\n",
        "print('size of original dataset', len(data))\n",
        "data.dropna(subset=['lyrics'],inplace=True)\n",
        "print('size of dataset without nan', len(data))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of original dataset 362237\n",
            "size of dataset without nan 266557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QivF1k4S42Ym",
        "colab_type": "text"
      },
      "source": [
        "## Split dataset\n",
        "\n",
        "I must split dataset before deal with unbalance dataset. Otherwise, when I oversampling dataset, I will add repetitions. As a result, my validation dataset and test dataset are not so valid.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJp8eZXm5ODt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shuffle the dataset\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# train= 80% | valid = 10% | test = 10%\n",
        "train_size = int(len(data)*0.8)\n",
        "val_size = int(len(data)*0.1)\n",
        "test_size = int(len(data)*0.1)\n",
        "train = data.loc[:train_size,:]\n",
        "val = data.loc[train_size:train_size + val_size , :]\n",
        "test = data.loc[train_size + val_size:, :]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srlFo-YNV8gz",
        "colab_type": "text"
      },
      "source": [
        "## Deal with unbalance dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfl5d9kM5GQ8",
        "colab_type": "code",
        "outputId": "3847b6a1-74a9-4978-ba93-17611b092cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# explore the number of each genre\n",
        "class_count = train['genre'].value_counts()\n",
        "print(type(class_count))\n",
        "class_count"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Rock             87304\n",
              "Pop              32383\n",
              "Hip-Hop          19950\n",
              "Metal            19185\n",
              "Not Available    19076\n",
              "Country          11455\n",
              "Jazz              6342\n",
              "Electronic        6316\n",
              "Other             4140\n",
              "R&B               2737\n",
              "Indie             2534\n",
              "Folk              1824\n",
              "Name: genre, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wniSp1IWYyo5",
        "colab_type": "code",
        "outputId": "6976071c-73db-4975-83e9-5783ebd319f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "class_count.plot(kind='bar')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe0bed2bf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAExCAYAAACeZs5sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAfoklEQVR4nO3debhdZX328e9NGALayGBEDUOiBhFQ\nBCKg1lZAJYAKVRAQhFKEt68goLYKtpdcBbHOA1bxpQKCWhAQyywgiGJlCpPIVCIIBBGQWZAh4X7/\neJ6T7JyciWStvc9wf65rX2evZ629f2sn5+zfesYl20RExMS2XK9PICIiei/JICIikgwiIiLJICIi\nSDKIiAiSDCIiAli+1yewtF760pd6+vTpvT6NiIgx45prrvmT7akD7RuzyWD69OnMmTOn16cRETFm\nSLprsH1pJoqIiCSDiIhIMoiICJIMIiKCJIOIiCDJICIiSDKIiAiSDCIigjE86Wwo0w89d6le9/vP\n79DwmUREjA2pGURERJJBREQkGUREBEkGERFBkkFERJBkEBERJBlERARJBhERQZJBRESQZBARESQZ\nREQESQYREUGSQUREMMJkIOljkm6S9FtJJ0uaLGmGpCslzZX0I0kr1mNXqttz6/7pHe9zWC2/TdK2\nHeWza9lcSYc2/SEjImJowyYDSdOAg4BZtjcCJgG7AV8Avmb7NcAjwL71JfsCj9Tyr9XjkLRBfd2G\nwGzg25ImSZoEfAvYDtgA2L0eGxERXTLSZqLlgZUlLQ+sAtwHbA2cXvefCOxUn+9Yt6n7t5GkWn6K\n7Wds3wnMBTavj7m277D9LHBKPTYiIrpk2GRg+17gy8DdlCTwGHAN8Kjt+fWwecC0+nwacE997fx6\n/Bqd5f1eM1h5RER0yUiaiVajXKnPAF4JvIjSzNN1kvaXNEfSnAcffLAXpxARMS6NpJnoHcCdth+0\n/RxwBvBWYNXabASwFnBvfX4vsDZA3f8S4KHO8n6vGax8CbaPtT3L9qypU6eO4NQjImIkRpIM7ga2\nlLRKbfvfBrgZ+Dmwcz1mb+DM+vysuk3df4lt1/Ld6mijGcBM4CrgamBmHZ20IqWT+axl/2gRETFS\nyw93gO0rJZ0OXAvMB64DjgXOBU6R9Nladlx9yXHA9yXNBR6mfLlj+yZJp1ISyXzgANsLACQdCFxA\nGal0vO2bmvuIERExnGGTAYDtw4HD+xXfQRkJ1P/Yp4FdBnmfo4CjBig/DzhvJOcSERHNywzkiIhI\nMoiIiCSDiIggySAiIkgyiIgIkgwiIoIkg4iIIMkgIiJIMoiICJIMIiKCJIOIiCDJICIiSDKIiAiS\nDCIigiSDiIggySAiIkgyiIgIkgwiIoIkg4iIIMkgIiJIMoiICJIMIiKCJIOIiCDJICIiSDKIiAiS\nDCIigiSDiIggySAiIkgyiIgIkgwiIoIkg4iIIMkgIiJIMoiICJIMIiKCJIOIiCDJICIiSDKIiAiS\nDCIighEmA0mrSjpd0q2SbpH0ZkmrS7pI0u3152r1WEk6WtJcSb+RtGnH++xdj79d0t4d5ZtJurG+\n5mhJav6jRkTEYEZaM/gG8FPb6wMbA7cAhwIX254JXFy3AbYDZtbH/sAxAJJWBw4HtgA2Bw7vSyD1\nmP06Xjd72T5WRES8EMMmA0kvAf4GOA7A9rO2HwV2BE6sh50I7FSf7wic5OIKYFVJrwC2BS6y/bDt\nR4CLgNl13xTbV9g2cFLHe0VERBeMpGYwA3gQOEHSdZK+K+lFwJq276vH/BFYsz6fBtzT8fp5tWyo\n8nkDlEdERJeMJBksD2wKHGN7E+BJFjUJAVCv6N386S1O0v6S5kia8+CDD7YdLiJiwhhJMpgHzLN9\nZd0+nZIc7q9NPNSfD9T99wJrd7x+rVo2VPlaA5QvwfaxtmfZnjV16tQRnHpERIzEsMnA9h+BeyS9\nthZtA9wMnAX0jQjaGzizPj8L2KuOKtoSeKw2J10AvEvSarXj+F3ABXXf45K2rKOI9up4r4iI6ILl\nR3jcR4EfSloRuAPYh5JITpW0L3AX8IF67HnA9sBc4Kl6LLYflnQkcHU97gjbD9fnHwG+B6wMnF8f\nERHRJSNKBravB2YNsGubAY41cMAg73M8cPwA5XOAjUZyLhER0bzMQI6IiCSDiIhIMoiICJIMIiKC\nJIOIiCDJICIiSDKIiAiSDCIigiSDiIggySAiIkgyiIgIkgwiIoIkg4iIIMkgIiJIMoiICJIMIiKC\nJIOIiCDJICIiSDKIiAiSDCIigiSDiIggySAiIkgyiIgIkgwiIoIkg4iIIMkgIiJIMoiICJIMIiKC\nJIOIiCDJICIiSDKIiAiSDCIigiSDiIggySAiIkgyiIgIkgwiIoIkg4iIIMkgIiJIMoiICF5AMpA0\nSdJ1ks6p2zMkXSlprqQfSVqxlq9Ut+fW/dM73uOwWn6bpG07ymfXsrmSDm3u40VExEi8kJrBwcAt\nHdtfAL5m+zXAI8C+tXxf4JFa/rV6HJI2AHYDNgRmA9+uCWYS8C1gO2ADYPd6bEREdMmIkoGktYAd\ngO/WbQFbA6fXQ04EdqrPd6zb1P3b1ON3BE6x/YztO4G5wOb1Mdf2HbafBU6px0ZERJeMtGbwdeCT\nwPN1ew3gUdvz6/Y8YFp9Pg24B6Duf6wev7C832sGK1+CpP0lzZE058EHHxzhqUdExHCGTQaS3g08\nYPuaLpzPkGwfa3uW7VlTp07t9elERIwby4/gmLcC75W0PTAZmAJ8A1hV0vL16n8t4N56/L3A2sA8\nScsDLwEe6ijv0/mawcojIqILhq0Z2D7M9lq2p1M6gC+xvQfwc2DnetjewJn1+Vl1m7r/Etuu5bvV\n0UYzgJnAVcDVwMw6OmnFGuOsRj5dRESMyEhqBoP5FHCKpM8C1wHH1fLjgO9Lmgs8TPlyx/ZNkk4F\nbgbmAwfYXgAg6UDgAmAScLztm5bhvCIi4gV6QcnA9qXApfX5HZSRQP2PeRrYZZDXHwUcNUD5ecB5\nL+RcIiKiOZmBHBERSQYREZFkEBERJBlERARJBhERQZJBRESQZBARESQZREQESQYREUGSQUREkGQQ\nEREkGUREBMu2amkA0w89d6le9/vP79DwmURELL3UDCIiIskgIiKSDCIigiSDiIggySAiIkgyiIgI\nkgwiIoIkg4iIIMkgIiJIMoiICJIMIiKCJIOIiCDJICIiSDKIiAiSDCIigiSDiIggySAiIkgyiIgI\nkgwiIoIkg4iIIMkgIiJIMoiICJIMIiKCJIOIiCDJICIiGEEykLS2pJ9LulnSTZIOruWrS7pI0u31\n52q1XJKOljRX0m8kbdrxXnvX42+XtHdH+WaSbqyvOVqS2viwERExsJHUDOYDn7C9AbAlcICkDYBD\ngYttzwQurtsA2wEz62N/4BgoyQM4HNgC2Bw4vC+B1GP263jd7GX/aBERMVLDJgPb99m+tj5/ArgF\nmAbsCJxYDzsR2Kk+3xE4ycUVwKqSXgFsC1xk+2HbjwAXAbPrvim2r7Bt4KSO94qIiC54QX0GkqYD\nmwBXAmvavq/u+iOwZn0+Dbin42XzatlQ5fMGKI+IiC5ZfqQHSnox8GPgENuPdzbr27Ykt3B+/c9h\nf0rTE+uss07b4Ual6Yeeu1Sv+/3nd2j4TCJiPBlRzUDSCpRE8EPbZ9Ti+2sTD/XnA7X8XmDtjpev\nVcuGKl9rgPIl2D7W9izbs6ZOnTqSU4+IiBEYtmZQR/YcB9xi+6sdu84C9gY+X3+e2VF+oKRTKJ3F\nj9m+T9IFwOc6Oo3fBRxm+2FJj0vaktL8tBfwzQY+WzSg2zWR1HwiemMkzURvBT4E3Cjp+lr2aUoS\nOFXSvsBdwAfqvvOA7YG5wFPAPgD1S/9I4Op63BG2H67PPwJ8D1gZOL8+IiKiS4ZNBrZ/BQw27n+b\nAY43cMAg73U8cPwA5XOAjYY7l4iIaEdmIEdERJJBREQkGUREBEkGERFBkkFERJBkEBERJBlERARJ\nBhERQZJBRESQZBARESQZREQESQYREUGSQUREkGQQEREkGUREBC/gHsgR41HurBZRpGYQERFJBhER\nkWQQEREkGUREBEkGERFBkkFERJBkEBERJBlERARJBhERQZJBRESQZBAREWRtooiu6vZaSFl7KUYq\nNYOIiEgyiIiIJIOIiCDJICIiSAdyRDQoHdZjV2oGERGRZBAREUkGERFB+gwiYgwbC5P4xkp/SGoG\nERGRmkFExGjU7VrPqKkZSJot6TZJcyUd2uvziYiYSEZFMpA0CfgWsB2wAbC7pA16e1YRERPHqEgG\nwObAXNt32H4WOAXYscfnFBExYch2r88BSTsDs21/uG5/CNjC9oH9jtsf2L9uvha4bSnCvRT40zKc\n7miNlXiJl3gTJ97SxlrX9tSBdoypDmTbxwLHLst7SJpje1ZDpzRqYiVe4iXexInXRqzR0kx0L7B2\nx/ZatSwiIrpgtCSDq4GZkmZIWhHYDTirx+cUETFhjIpmItvzJR0IXABMAo63fVNL4ZapmWkUx0q8\nxEu8iROv8VijogM5IiJ6a7Q0E0VERA8lGURERJJBREQkGcQoJmk9SRdL+m3dfoOkf2055hptvn9H\nnN9J+sd+Zed0I3Y3SFpO0lt6fR7dImmVLsRYaYCy1Zt6/wmRDCQd0W97kqQfthRrsqSPSzpD0o8l\nfUzS5DZidcTcVNJBkj4qadOWYpwt6azBHm3EBP4TOAx4DsD2byjDjtt0haTTJG0vSS3GeQ7YStIJ\ndTg1wLQW4wEg6URJq3Zsrybp+Kbj2H6est5YV0h6qaTD69/BiyUdI+m3ks6U9JoW475F0s3ArXV7\nY0nfbincGZJW6Ij9CuCipt58QiQDYG1Jh8HC7HoGcHtLsU4CNgS+CfwHZeG977cUC0mfAU4E1qBM\nUT+hpavnLwNfGeLRhlVsX9WvbH5LsfqsRxm29yHgdkmfk7ReC3Gesr0rcAtwmaR1gG4M7XuD7Uf7\nNmw/AmzSUqyLJb2/5aTa57+AlYCZwFXAHcDOwDnAd1uM+zVgW+AhANs3AH/TUqz/Bk6tF7PTKUPx\nD2vs3W2P+wcgyi/LYcCFwCEtxrp5JGUNxrsNmNyxvTJwW6//zRv6bOcDrwaurds7A+d3Mf5WlJnw\njwK/AN7c4Htf1/H8HZQrywe68JluAFbr2F4duLGlWE8Az1NqQY/X7cfb+lz1p4C7++27vsV/zysH\n+P+8ocV4BwBnAzcCb2nyvUfFpLO29Gsy+Qbw/4D/AX4paVPb17YQ9lpJW9q+op7DFsCcFuL0+QMw\nGXi6bq9Ei0t5SJoJ/DulxrOw+cv2q1oIdwDlKn19SfcCdwJ7thBnodpnsCelZnA/8FHKbPg3AqcB\nMxoK9Zm+J7Z/JmlbYO+G3nsoXwEul3Qa5YtzZ+CoNgLZ/qs23ncQC2pMS+q/gNvzLca9p/aNuDbh\nHEyp7TVG0sc7N4F1gOuBLet3zVebiDOukwFLNl88QvkS+wqlSr51CzE3A34t6e66vQ5wm6QbKb+r\nb2g43mPATZIuonymdwJXSTqaEvCghuOdABxOqR5vBexDS82Ntu8A3iHpRcBytp9oI04/l1Oa9Xay\nPa+jfI6k7zQY5xBJC2yfB2D7LklrNfj+A7J9kqQ5LPrdf5/tm9uIVZuH9gBm2D5S0trAK7xk018T\nXlX7rtTxnLrdVAIfyD9SLjSnUS7CLqRcxDSpf1I9Y5DyZZIZyA2TtO5Q+23f1XC8Ia8mbZ/YcLxr\nbG8m6Ubbr+8sazDGx4fa39SV0ABxJwFftP2JNt6/X6w7gHuAS2z/Wy271nZbAwCm2H58sNEnth9u\nIeYxlKvyrW2/TtJqwIW239RCrL8dar/tXzQdc7wZ7zUDACR9jvJH/mjdXg34hO3GO1rrFd7GwNtq\n0WUunUqtsH1iHY3S18l5m+3n2ooHPCNpOUrn6oGUq6EXNxyjm80LC9le0MXhkI8C2wBHSzqblpu/\nKH1m7wauYfGOatXtNpr5trC9qaTroHRWd4ycatRQX/ZtDBeW9EnbX5T0TQbo+G+yRl5/Pwa9arf9\n3ibiTIhkAGxn+9N9G/WXcnug8WQg6WBgPxZV5X4g6Vjb32w6Vo33dspoot9T/rDXlrS37V+2EY/S\nJroKcBBwJKWpaK8mA/RdKffI9bWJ4TTgyb5C22cM/pKlItvzgY9I+nvgV8BqDcdYyPa76882m0z6\ne67WtkrPrjSVdtvvF5L0O+Bc4AfA9yjNw03q6xdosz+wz5e7EGPCJINJklay/QyApJUpHa1t2Jdy\nRfRkjfUFSjt0K8mA0v/xLtu31XjrASdT+i7aMN321cCfKf0FSNoFuLLpQJJeRWmP3ZLyhXI58LHa\nl9CWyZRhgp39SWZRcm/Kwv4H29+rfUpNtzUPSNI0YF06/v5bung4GvgJ8DJJR1E6q1udNNjH9qsl\nfYzyO7NPC+9/dv3ZaDPsILEW1nrabAWYEH0Gkj4FvIfS+Qnll+Ms219sIdaNwJtsP123JwNX97Wv\ntxDvN/07pQcqazDeEu3abbV1S7qCMnHp5Fq0G/BR21s0Hasj5ltt/89wZQ3GexmLj8q6e4jDm4j3\nBWBX4GbqCJwStpmmhgHirU9pDhNwse1GR9p0xLkQ2K+vT07SlpQa85coF0sfaDheV5pu+sV8O/1a\nAYDGWgEmRDIAkDSbMp4b4CLbF7QU5+OUIYI/qUU7Ad+z/fWW4h1PqXr/oBbtAUyy/Q8Nx9kO2B74\nAPCjjl1TgA1sb95kvBpzoER3g+2Nm47V8f5dSXaS3gN8FXgl8ABl1NkttjdqMs4AcW+jTDx7ps04\nHfEmAWuyeC2k8YQn6Xrbb6zPd6AkgZ1s/6+kq5vutO7osH4f8HIW/f3tDtxv+2NNxqsxrwE+2L8V\noKnBGxOlmQjgOmAFSja/rq0gtr8q6VLgr2vRPrZbiwf8X0rzQl+H1WVAG9Ph/0BpH30vpROyzxNA\no7/4HSNezpd0KHAK5f9tV+C8JmN1xHwz8BZgar/RTFMoN1xq2mcpzV8/s72JpK1ovxMZyszcFYDW\nk4Gkj1KGId9PqYX0dVa3UWt9po6sW5syN2QT23+QNAV4UdPB+ppuJH3Fi9+L+Ow6dLcNK/QlgnoO\n/6uO5SmW1YSoGUj6AOVK4VLKL+TbgH+2fXqDMSZTxhy/hjI78LjaQTiu1F++5YF1On8xG45xJ+VL\nY6BlDNzGBLd6pfd2yv9h53yCJ4CzbTe6fInqDc0l3UD54nq+7VpPjftjYGPgYjoSQgvzUZA0l9J/\n9lDT7z1ArNcAhwLPAr+jzLf5NbAj8MMWhyPfAuzQ148laQZwnu3XtRCr1VaAiZIMbgDeafuBuj2V\nckXW2B+epB9Rpt1fBmwH/N72IU29/wDxbmToNsu2+gzeQxndsKLtGZLeCBzRVptzt0lat+m5IIPE\n+RmlCfHzlHWlHqD0NbU6tHWweSltdIRK+jnl767rF0WSNqE0C19n+2ctxplNmSV/B+XiZV3g/7TR\nDK2yrtoBLGp1uAz4dlNNfhMlGSycIFW3l6OsH9JYp26/SVjLA1e1NYGoxuib3CbKELrtO/e39YVW\n2y23Bi61vUktu7HJf8t+8TZiyaUvTmojVo23HvBPwHQWb+dudLa6ypLHT1P+//akNEf9sI3JXwPE\nbnVeSkcz24bAaym/n521kFau0gc5l+WA3W23skpxjbESsH7dvLXp/hhJ67Q9sAAmTp/BTyVdwKJR\nKbtSFkFr0sI/KNvz1fJCjZ1f9pKe6cbVbPWc7cf6fb5WrigkHU5putmA0lewHWU8fmvJgDK/4DuU\nlS4XDHPsCybpCZb89+r7x/xMHR//L7Yvbjp2jf922p+X0jdp8O76WLE+oL3flSmUq+ZplLWkLqrb\n/0RZnK+1ZEAZxj2d8n26saSmL1j+G9gUSjOf7fc3+N4LTYhkYPufJb2PRdWrY23/ZKjXLIWNJT1e\nnwtYuW6rnIKnNByvV26S9EHK3I2ZlI7rX7cUa2dK+/Z1tveRtCaL2kvbMt/2MW29uYdYvK2OvNmI\n8sXV1qii1ueleNHyGrvYPq1zX52T0obvU9Yeuxz4MPBpyt/eTravbykmkr5PWVn3ejqG6tLsBUvn\nlVcbM8WBCZIMYOEM0jOgVB0l7dFk1dF2GyNOBqXFV2RdubaRLvylcTsrskIZqfEvlGr/yZQ11Y9s\nKdZfasfq/Hrl9wBltEibzpb0EcrQ4M6mjdabb2wvAG5QWeKgLa2OSOnnMEpNa7iyJryqo5n2u8B9\nlEEOTw/9smU2izK0us32dg/yvFHjus9guKqj7R17eHrLpHbODcZNt3H3gsodoz5NmWz2Ccqs5+tt\nNz6jtCPmnQMUtzKCqRe6MS+lR3NSFpsL0tZEyAHingYcZPu+FmMsoCyNIsr9Sp7q20WDrQ7jPRmc\nyaKq4zbAyyj/gAe3WXUcjzTMrS3bHk2kcmenKS63voyl1PaIlBpjY8r9H75AmU8B5Q5191MGHjzS\nVKyOmH1fmLD4l2arzbT1ouyNlLurddYkx9zouvGeDDpH+Eyie1XHnlBZEG//lt77QcqSyydT1iFa\nvAe5wSWCNcx9nFtsAkPSgIvutTmCqVvq38BJtvdoOc4KlBvmfJjSUQ1lhvUJwKebHr3USxpk6ewm\n/x66Zbz3GXSO8Fkgad54TQTVrOEPWWovp0zk2R34IGW44Mm2b2oh1lD3VG7rpkR9OpctmEypUV5L\nuyOYuqL+DawraUXbz7YY6ouUZc3Xdb0hUW2y/XJ9HNxi7K4ai1/6gxnvNYOeVB17RdJPbc/uQpyV\nKEnhS8C/2f6PtmP2iqRVgVO68e/aDZJOAl5H6UPrXKK7sbH/km4H1uvfqVprJrfantlUrF4ZZIgw\njOHvlnFdM+j2CJ9eqldebQ3b64uxErADJRFMZ9ESxU3H2dr2JXU48BLc/L0FhvIktHrbxG77XX0s\nx6L5AE1fEXqg0TW1ZjIurj6HGiI8Vo3rZDARSHoTcDz1D1vSY8A/2L5myBe+8DgnUca+n0epDfy2\nyffv52+BSyjLjvfXxr0FFtLiSxNPolxFn9pWvB64uQtj/2+WtFf/fhZJewK3NhwrGjKum4kmAkm/\nAQ6wfVnd/mvK6JBG1yaS9DyLmhWWuG3iWKwWD6Rfh+B84C7b83p1Pk0baMhl08MwVW6ecwbwFxat\ncDuL0kz7d7bvbSpWNCc1g7FvQV8iALD9K0mNLwxme7mm33MkVNam35DF1yY6oq14tn9RZzr3dSQ3\nulppr3SM/Z8m6eiOXVMoSa8x9ct+C0lbU/7voKzk2coSG9GM1AzGOElfp1xxncyiNf+fpk4qanMY\nZtskfYdyv+WtKGsF7UxZAHDfFmO2vtx5L3SM/T8C+EzHrieAn7cx9j/GliSDMW48z0RWvdNZx88X\nA+fbfluLMVtf7ryX6kCDJ+vSF30jfFay/dTQr4zxLs1EY5ztrXp9Di36S/35lKRXUm5U/4qWYy7X\nlwiqhygjb8aLCynr/P+5bq9cy1q9j0KMfkkGY5SkPW3/QIvfonGhJseN99A5dZz/lygTvwz8Z8sx\nB1ruvJVbbfbIZNt9iQDbf673VogJLslg7Oq7r+u4G+/cx3bfaqg/lnQO5YvssTZiqdw2cU0vudz5\n5bS7Fn63PSlp076+JEmbsagGFhNY+gxi1KrDZk8BfmT7dy3HOgc4zPaN/cpfD3zO9kBzHsacOi/l\nFOAPlA7ylwO7Nj0vJcaeJIMxqt/wwCW4hRucd5vKrT13rY/nKcshn+oWbgEo6WrbbxpkX2u39eyF\nupDca+tm47e9jLFpPHWMTTTXdDze2297XFzl2b7L9hdtb0ZZHO8NwED3G2jCqkPsW7mlmF1X+wc+\nRVnG/bfAdEnv7vFpxSiQPoMxyvaJfc8lHdK5PZ70qx0sAD7ZUqg5kvazvVgHtaQPM06Sa3UC5fO8\nuW7fS7nz2Dk9O6MYFZIMxodx2dYn6UpgBcraQLvYvqPFcIcAP5G0B4svobAi8Hctxu22V9veVdLu\nALafkqThXhTjX5JBjGZ7ueN+vQCS1rR9f9OB6nu+RdJWLLoZ/bm2L2k6Vo89K2ll6gWEpFfTcYeu\nmLjSgTxG9VtPfRVaui/qaFDnGryf0m/wOtuv7PEpjVmS3gn8K7ABZbLZW4G/t31pL88rei/JIEal\nevW6IyUBbEKZT7ET8Evbz/fy3MY6SWsAW1IuHK6w/acen1KMAkkGMepI+i/KAnEXUsbEXwLMtT2e\nbjLTVb28r3SMDekziNFoA+AR4BbglvF0h6we6uV9pWMMSM0gRiVJ61Nur7kr8CfKJKmN2ug8johM\nOotRyvattg+3vT5wMHAicLWkX/f41MYkSZ/seL5Lv32f6/4ZxWiTmkGMGXU8/Nts/7LX5zLWdN7a\nsv9tLpu+7WWMTekziDHD5coliWDpaJDnA23HBJRmooiJwYM8H2g7JqA0E8WoJWmG7TuHK4vhSVoA\nPEmpBazM4pMUJ9teoVfnFqNDkkGMWgO1ZUu6pq5iGhENSp9BjDp1WOmGwEvqXcf6TAEm9+asIsa3\nJIMYjV4LvJtyj4HOO4w9AezXkzOKGOfSTBSjlqQ327681+cRMRFkNFGMZvdI+omkB+rjx5LW6vVJ\nRYxHSQYxmp0AnAW8sj7OrmUR0bA0E8WoJekG2xv3K7ve9ht7dU4R41VqBjGa/UnSnpIm1ceewEO9\nPqmI8Sg1gxi1JK0LfJNy83YDvwYOsn13T08sYhxKMoiIiMwziNFH0meG2G3bR3btZCImiNQMYtSR\n9IkBil8E7AusYfvFXT6liHEvySBGNUl/Rbm5zb7AqcBXbD/Q27OKGH/STBSjkqTVgY8De1Ducrap\n7Ud6e1YR41eSQYw6kr4EvA84Fni97T/3+JQixr00E8WoI+l54BlgPovfeEWUDuQpPTmxiHEsySAi\nIjIDOSIikgwiIoIkg4iIIMkgIiJIMoiICJIMIiIC+P+h3gxbSWBV+QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIEqEL5afaFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "delete_index = train[train['genre'] == 'Rock'].index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61GM-yW-ft56",
        "colab_type": "code",
        "outputId": "7f647f2d-7a4c-46f7-8db4-a7dedddf300b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(delete_index)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.indexes.numeric.Int64Index"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEr7hpHWhA1a",
        "colab_type": "code",
        "outputId": "7194db56-9d8e-484f-981c-9ad3fe164155",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "delete_index[:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([0, 5, 6, 7, 8, 9, 11, 12, 13, 16], dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCsZB5Qrf6zT",
        "colab_type": "code",
        "outputId": "c473c77b-b98d-464d-cc37-ce5837938576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "train.drop(delete_index[0:60000], inplace=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4117: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRfulfv0glWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enhence_attributes = ['Folk', 'Indie','R&B']\n",
        "for attr in enhence_attributes:\n",
        "    tmp_data = train[train['genre'] == attr]\n",
        "    for i in range(8):\n",
        "        train = train.append(tmp_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah0MLvMG1Oz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enhence_attributes = ['Jazz', 'Electronic','Other']\n",
        "for attr in enhence_attributes:\n",
        "    tmp_data = train[train['genre'] == attr]\n",
        "    for i in range(4):\n",
        "        train = train.append(tmp_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9nfSX4Ff9uO",
        "colab_type": "code",
        "outputId": "bf190a36-8a8d-40ec-8682-9d21424b3575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "source": [
        "# explore the number of each genre\n",
        "class_count = train['genre'].value_counts()\n",
        "print(type(class_count))\n",
        "print(class_count)\n",
        "class_count.plot(kind='bar')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "Pop              32383\n",
            "Jazz             31710\n",
            "Electronic       31580\n",
            "Rock             27304\n",
            "R&B              24633\n",
            "Indie            22806\n",
            "Other            20700\n",
            "Hip-Hop          19950\n",
            "Metal            19185\n",
            "Not Available    19076\n",
            "Folk             16416\n",
            "Country          11455\n",
            "Name: genre, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe0bed40b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAExCAYAAACeZs5sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMcXnKA0Ced1",
        "colab_type": "text"
      },
      "source": [
        "## Fraction\n",
        "\n",
        "I start with a small dataset, 5% in order to build a pipline quickly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCBm2lRzEf8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reset the index, otherwise, we will encounter errors \n",
        "#test.reset_index(drop=True, inplace=True)\n",
        "#val.reset_index(drop=True, inplace=True)\n",
        "\n",
        "#\n",
        "train = train.sample(frac=1).reset_index(drop=True)\n",
        "val = val.sample(frac=1).reset_index(drop=True)\n",
        "test = test.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXG2vf7RCdgz",
        "colab_type": "code",
        "outputId": "84ac9563-696a-4878-e912-e153f5c7d3cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "ratio = 0.8\n",
        "train_sample = train.loc[:int(len(train)*ratio),:]\n",
        "val_sample = val.loc[:int(len(val)*ratio),:]\n",
        "test_sample = test.loc[:int(len(test)*ratio),:]\n",
        "\n",
        "print('size of train_sample', len(train_sample))\n",
        "print('size of val_sample', len(val_sample))\n",
        "print('size of test_sample', len(test_sample))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of train_sample 221759\n",
            "size of val_sample 21325\n",
            "size of test_sample 21326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0D9ja7B_9ud",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAb3ogfyAA2m",
        "colab_type": "code",
        "outputId": "e5b2319f-af42-436b-b66c-e5d546208139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def clean_context(ctx_in, has_target=False):\n",
        "            replace_newline = re.compile(\"\\n\")\n",
        "            replace_dot = re.compile(\"\\.\")\n",
        "            replace_cite = re.compile(\"'\")\n",
        "            replace_frac = re.compile(\"[\\d]*frac[\\d]+\")\n",
        "            replace_num = re.compile(\"\\s\\d+\\s\")\n",
        "            rm_context_tag = re.compile('<.{0,1}context>')\n",
        "            rm_cit_tag = re.compile('\\[[eb]quo\\]')\n",
        "            rm_misc = re.compile(\"[\\[\\]\\$`()%/,\\.:;-]\")\n",
        "\n",
        "            ctx = replace_newline.sub(' ', ctx_in)  # (' <eop> ', ctx)\n",
        "\n",
        "            ctx = replace_dot.sub(' ', ctx)  # .sub(' <eos> ', ctx)\n",
        "            ctx = replace_cite.sub(' ', ctx)  # .sub(' <cite> ', ctx)\n",
        "            ctx = replace_frac.sub(' <frac> ', ctx)\n",
        "            ctx = replace_num.sub(' <number> ', ctx)\n",
        "            ctx = rm_cit_tag.sub(' ', ctx)\n",
        "            ctx = rm_context_tag.sub('', ctx)\n",
        "            ctx = rm_misc.sub('', ctx)\n",
        "\n",
        "            word_list = [word for word in re.split('`|, | +|\\? |! |: |; |\\(|\\)|_|,|\\.|\"|“|”|\\'|\\'', ctx.lower()) if word]\n",
        "            return word_list\n",
        "\n",
        "def lemmatize_data(input_data):\n",
        "    # input is a list of string\n",
        "    result = []\n",
        "    wnl = WordNetLemmatizer()\n",
        "    for token in input_data:\n",
        "        result.append(wnl.lemmatize(token))\n",
        "    return result \n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def preprocess(Corpus,attr='lyrics'):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    # Remove blank rows if any.\n",
        "    Corpus[attr].dropna(inplace=True)\n",
        "    Corpus[attr] = [lemmatize_data(clean_context(entry)) for entry in Corpus[attr]]\n",
        "    Corpus[attr] = [' '.join([token for token in entry if token not in stop_words]) for entry in Corpus[attr]]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vRTfEf-D_Ak",
        "colab_type": "code",
        "outputId": "87f0876b-5b1a-4ab9-88c0-75d635115ef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "preprocess(train_sample)\n",
        "preprocess(val_sample)\n",
        "preprocess(test_sample)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/series.py:4787: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._update_inplace(result)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWsM4IHNjYSj",
        "colab_type": "code",
        "outputId": "bae2f1da-81c2-476c-c9c6-ea9f2a43e39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "train_sample"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>140917</td>\n",
              "      <td>hands-down</td>\n",
              "      <td>2015</td>\n",
              "      <td>dej-loaf</td>\n",
              "      <td>Other</td>\n",
              "      <td>verse 1 hand nigga gettin bread yea basquiat p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>253286</td>\n",
              "      <td>purify</td>\n",
              "      <td>2007</td>\n",
              "      <td>feeder</td>\n",
              "      <td>Rock</td>\n",
              "      <td>given everything innocence ha pulled u apart f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>493</td>\n",
              "      <td>my-belle</td>\n",
              "      <td>2015</td>\n",
              "      <td>cenk-r-lr-etin</td>\n",
              "      <td>Other</td>\n",
              "      <td>hug meä± sacrifice ä± love methis life sake wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14707</td>\n",
              "      <td>how-was-i-supposed-to-know</td>\n",
              "      <td>2011</td>\n",
              "      <td>cris-cab</td>\n",
              "      <td>Pop</td>\n",
              "      <td>picture armed know stabbing dark place go page...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>361371</td>\n",
              "      <td>honey</td>\n",
              "      <td>2007</td>\n",
              "      <td>dean-martin</td>\n",
              "      <td>Jazz</td>\n",
              "      <td>see tree big grown friend long big laughed got...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221754</th>\n",
              "      <td>177031</td>\n",
              "      <td>the-city</td>\n",
              "      <td>2013</td>\n",
              "      <td>colin</td>\n",
              "      <td>Indie</td>\n",
              "      <td>chorus like city go round thing like city like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221755</th>\n",
              "      <td>335014</td>\n",
              "      <td>take-me-back-home</td>\n",
              "      <td>2010</td>\n",
              "      <td>escape-directors</td>\n",
              "      <td>Folk</td>\n",
              "      <td>board train take east find western wind drove ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221756</th>\n",
              "      <td>90341</td>\n",
              "      <td>ton-visage</td>\n",
              "      <td>2016</td>\n",
              "      <td>frasro-delavega</td>\n",
              "      <td>Other</td>\n",
              "      <td>quand en ville le grain se lã¨ve vent de nerf ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221757</th>\n",
              "      <td>19319</td>\n",
              "      <td>the-prime-time-of-your-life</td>\n",
              "      <td>2005</td>\n",
              "      <td>daft-punk</td>\n",
              "      <td>Electronic</td>\n",
              "      <td>prime time life prime time life prime time lif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221758</th>\n",
              "      <td>337452</td>\n",
              "      <td>grasshopper</td>\n",
              "      <td>2014</td>\n",
              "      <td>camper-van-beethoven</td>\n",
              "      <td>Rock</td>\n",
              "      <td>400 mile mexican coast got lot waggle rainbow ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>221759 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         index  ...                                             lyrics\n",
              "0       140917  ...  verse 1 hand nigga gettin bread yea basquiat p...\n",
              "1       253286  ...  given everything innocence ha pulled u apart f...\n",
              "2          493  ...  hug meä± sacrifice ä± love methis life sake wa...\n",
              "3        14707  ...  picture armed know stabbing dark place go page...\n",
              "4       361371  ...  see tree big grown friend long big laughed got...\n",
              "...        ...  ...                                                ...\n",
              "221754  177031  ...  chorus like city go round thing like city like...\n",
              "221755  335014  ...  board train take east find western wind drove ...\n",
              "221756   90341  ...  quand en ville le grain se lã¨ve vent de nerf ...\n",
              "221757   19319  ...  prime time life prime time life prime time lif...\n",
              "221758  337452  ...  400 mile mexican coast got lot waggle rainbow ...\n",
              "\n",
              "[221759 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBqizFJACj1P",
        "colab_type": "text"
      },
      "source": [
        "## Encode label and tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8o_cOYrDKN5",
        "colab_type": "text"
      },
      "source": [
        "### Build the dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WszmBHhDvMI",
        "colab_type": "code",
        "outputId": "86adbafd-0aec-4e22-ce1d-3b7d963ffafd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from collections import Counter\n",
        "# Frequent count, keep the tokens above the threshold\n",
        "\n",
        "\n",
        "count_words = Counter()\n",
        "\n",
        "for words in train_sample['lyrics']:\n",
        "    count_words.update(words.split(' '))\n",
        "\n",
        "total_words = len(count_words)\n",
        "sorted_words = count_words.most_common(total_words)\n",
        "\n",
        "threshold = 20\n",
        "\n",
        "print('original dictionaary size', total_words)\n",
        "token_to_int = {}\n",
        "token_to_int = {w:i+1 for i,(w,c) in enumerate(sorted_words) if c >= threshold}\n",
        "token_to_int['PAD'] = 0\n",
        "\n",
        "print('filtered dictionaary size', len(token_to_int))\n",
        "token_to_int['UNK'] = len(token_to_int)\n",
        "\n",
        "label_to_int = {}\n",
        "for label in data['genre']:\n",
        "    if label not in label_to_int:\n",
        "        label_to_int[label] = len(label_to_int)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original dictionaary size 350074\n",
            "filtered dictionaary size 41011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wQ6AOeqSC-S",
        "colab_type": "code",
        "outputId": "6727de01-ad70-4bd6-8385-c1673a8440d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "token_to_int['PAD']"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89O6eRVNDO6H",
        "colab_type": "text"
      },
      "source": [
        "### Encoding **function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqJlFc3yCoKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(words,token_to_int):\n",
        "    result = []\n",
        "    for token in words.split(' '):\n",
        "        if token not in token_to_int:\n",
        "            result.append(token_to_int['UNK'])\n",
        "        else:\n",
        "            result.append(token_to_int[token])\n",
        "    return result\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58o8iQOkhQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datas = train_sample['lyrics'][0].split(' ')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB1cRJ37kqDw",
        "colab_type": "code",
        "outputId": "3f44232b-6017-4e96-b10c-a97ffaa29549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "token_to_int['hello']"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvaxMaUokVnK",
        "colab_type": "code",
        "outputId": "9c213822-f420-45d4-aa0e-5fe3bffcb0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3060
        }
      },
      "source": [
        "encode(train_sample['lyrics'][0], token_to_int)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[226,\n",
              " 618,\n",
              " 63,\n",
              " 53,\n",
              " 487,\n",
              " 1469,\n",
              " 643,\n",
              " 41011,\n",
              " 3141,\n",
              " 327,\n",
              " 10593,\n",
              " 1963,\n",
              " 1409,\n",
              " 122,\n",
              " 932,\n",
              " 319,\n",
              " 1375,\n",
              " 938,\n",
              " 3555,\n",
              " 440,\n",
              " 3201,\n",
              " 4051,\n",
              " 917,\n",
              " 863,\n",
              " 3673,\n",
              " 2,\n",
              " 5043,\n",
              " 203,\n",
              " 2090,\n",
              " 2007,\n",
              " 53,\n",
              " 1,\n",
              " 53,\n",
              " 4321,\n",
              " 70,\n",
              " 3,\n",
              " 30,\n",
              " 9557,\n",
              " 62,\n",
              " 3572,\n",
              " 20963,\n",
              " 3572,\n",
              " 643,\n",
              " 2414,\n",
              " 74,\n",
              " 35,\n",
              " 136,\n",
              " 576,\n",
              " 108,\n",
              " 801,\n",
              " 11283,\n",
              " 54,\n",
              " 5916,\n",
              " 370,\n",
              " 16,\n",
              " 17038,\n",
              " 1673,\n",
              " 568,\n",
              " 826,\n",
              " 18,\n",
              " 1845,\n",
              " 2,\n",
              " 384,\n",
              " 228,\n",
              " 20,\n",
              " 92,\n",
              " 185,\n",
              " 456,\n",
              " 34171,\n",
              " 18,\n",
              " 63,\n",
              " 53,\n",
              " 487,\n",
              " 1469,\n",
              " 22,\n",
              " 1195,\n",
              " 93,\n",
              " 441,\n",
              " 1273,\n",
              " 74,\n",
              " 191,\n",
              " 74,\n",
              " 344,\n",
              " 136,\n",
              " 1983,\n",
              " 86,\n",
              " 13,\n",
              " 8,\n",
              " 146,\n",
              " 54,\n",
              " 226,\n",
              " 555,\n",
              " 8820,\n",
              " 114,\n",
              " 1473,\n",
              " 6714,\n",
              " 3220,\n",
              " 4020,\n",
              " 764,\n",
              " 783,\n",
              " 498,\n",
              " 24,\n",
              " 105,\n",
              " 134,\n",
              " 24,\n",
              " 2793,\n",
              " 73,\n",
              " 81,\n",
              " 27,\n",
              " 166,\n",
              " 495,\n",
              " 211,\n",
              " 13,\n",
              " 114,\n",
              " 2681,\n",
              " 5280,\n",
              " 235,\n",
              " 91,\n",
              " 1050,\n",
              " 226,\n",
              " 569,\n",
              " 562,\n",
              " 491,\n",
              " 69,\n",
              " 603,\n",
              " 16,\n",
              " 591,\n",
              " 136,\n",
              " 16,\n",
              " 2058,\n",
              " 1214,\n",
              " 20,\n",
              " 4704,\n",
              " 105,\n",
              " 8,\n",
              " 591,\n",
              " 3744,\n",
              " 34171,\n",
              " 226,\n",
              " 1201,\n",
              " 1362,\n",
              " 1395,\n",
              " 584,\n",
              " 4899,\n",
              " 1141,\n",
              " 2075,\n",
              " 11343,\n",
              " 398,\n",
              " 391,\n",
              " 211,\n",
              " 696,\n",
              " 105,\n",
              " 228,\n",
              " 209,\n",
              " 229,\n",
              " 20964,\n",
              " 6,\n",
              " 90,\n",
              " 398,\n",
              " 90,\n",
              " 733,\n",
              " 89,\n",
              " 10,\n",
              " 41011,\n",
              " 5869,\n",
              " 67,\n",
              " 1293,\n",
              " 3,\n",
              " 318,\n",
              " 5035,\n",
              " 1687,\n",
              " 10,\n",
              " 6594,\n",
              " 11,\n",
              " 105,\n",
              " 387,\n",
              " 26,\n",
              " 444,\n",
              " 34171]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL4emPt9Qu3s",
        "colab_type": "code",
        "outputId": "86bc8d88-d0e8-428a-a09c-001c33d5ef3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "# encode lyrics\n",
        "train_sample['lyrics'] = [encode(words, token_to_int) for words in train_sample['lyrics']]\n",
        "val_sample['lyrics'] = [encode(words, token_to_int) for words in val_sample['lyrics']]\n",
        "test_sample['lyrics'] = [encode(words, token_to_int) for words in test_sample['lyrics']]\n",
        "\n",
        "# encode labels\n",
        "train_sample['genre'] = [label_to_int[label] for label in train_sample['genre']]\n",
        "val_sample['genre'] = [label_to_int[label] for label in val_sample['genre']]\n",
        "test_sample['genre'] = [label_to_int[label] for label in test_sample['genre']]\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YnFuTRPRBOb",
        "colab_type": "code",
        "outputId": "b4f0d09b-3462-4182-bfea-80aaf01214b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#check\n",
        "val_sample"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>204743</td>\n",
              "      <td>cumberland-river</td>\n",
              "      <td>2008</td>\n",
              "      <td>dailey-and-vincent</td>\n",
              "      <td>1</td>\n",
              "      <td>[120, 116, 6369, 25903, 3103, 1916, 23785, 224...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>328109</td>\n",
              "      <td>in-bloom</td>\n",
              "      <td>2008</td>\n",
              "      <td>dark-lotus</td>\n",
              "      <td>5</td>\n",
              "      <td>[12108, 69, 1059, 2368, 207, 125, 15986, 41011...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11531</td>\n",
              "      <td>wine</td>\n",
              "      <td>2007</td>\n",
              "      <td>conway-twitty</td>\n",
              "      <td>0</td>\n",
              "      <td>[676, 379, 385, 676, 379, 385, 676, 379, 385, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>217096</td>\n",
              "      <td>burning-down-the-billboards</td>\n",
              "      <td>2007</td>\n",
              "      <td>cave-in</td>\n",
              "      <td>0</td>\n",
              "      <td>[21706, 114, 630, 7, 114, 3400, 63, 1452, 2352...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>282454</td>\n",
              "      <td>things-will-change</td>\n",
              "      <td>2014</td>\n",
              "      <td>gallon-drunk</td>\n",
              "      <td>0</td>\n",
              "      <td>[36, 153, 267, 16, 13, 153, 267, 18, 267, 1364...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21320</th>\n",
              "      <td>113534</td>\n",
              "      <td>coma</td>\n",
              "      <td>2007</td>\n",
              "      <td>eighteen-visions</td>\n",
              "      <td>0</td>\n",
              "      <td>[386, 10743, 1852, 344, 196, 144, 524, 60, 98,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21321</th>\n",
              "      <td>318593</td>\n",
              "      <td>i-m-your-woman</td>\n",
              "      <td>2007</td>\n",
              "      <td>connie-smith</td>\n",
              "      <td>2</td>\n",
              "      <td>[148, 66, 11928, 4, 59, 209, 3365, 425, 27, 49...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21322</th>\n",
              "      <td>28859</td>\n",
              "      <td>to-a-friend</td>\n",
              "      <td>2007</td>\n",
              "      <td>alexisonfire</td>\n",
              "      <td>3</td>\n",
              "      <td>[346, 8, 5, 2887, 1423, 418, 55, 3873, 50, 411...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21323</th>\n",
              "      <td>77151</td>\n",
              "      <td>walk-forever-by-my-side</td>\n",
              "      <td>2007</td>\n",
              "      <td>the-alarm</td>\n",
              "      <td>0</td>\n",
              "      <td>[148, 188, 174, 15, 268, 586, 25, 108, 2306, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21324</th>\n",
              "      <td>298304</td>\n",
              "      <td>highway-patrol</td>\n",
              "      <td>2008</td>\n",
              "      <td>brown-junior</td>\n",
              "      <td>3</td>\n",
              "      <td>[6, 162, 359, 9, 1036, 394, 1055, 31, 5403, 47...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21325 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        index  ...                                             lyrics\n",
              "0      204743  ...  [120, 116, 6369, 25903, 3103, 1916, 23785, 224...\n",
              "1      328109  ...  [12108, 69, 1059, 2368, 207, 125, 15986, 41011...\n",
              "2       11531  ...  [676, 379, 385, 676, 379, 385, 676, 379, 385, ...\n",
              "3      217096  ...  [21706, 114, 630, 7, 114, 3400, 63, 1452, 2352...\n",
              "4      282454  ...  [36, 153, 267, 16, 13, 153, 267, 18, 267, 1364...\n",
              "...       ...  ...                                                ...\n",
              "21320  113534  ...  [386, 10743, 1852, 344, 196, 144, 524, 60, 98,...\n",
              "21321  318593  ...  [148, 66, 11928, 4, 59, 209, 3365, 425, 27, 49...\n",
              "21322   28859  ...  [346, 8, 5, 2887, 1423, 418, 55, 3873, 50, 411...\n",
              "21323   77151  ...  [148, 188, 174, 15, 268, 586, 25, 108, 2306, 8...\n",
              "21324  298304  ...  [6, 162, 359, 9, 1036, 394, 1055, 31, 5403, 47...\n",
              "\n",
              "[21325 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yGmj7eWCr0e",
        "colab_type": "text"
      },
      "source": [
        "## Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGEx0LeIZp7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(data, pad_length=100, left=True):\n",
        "    features = [0 for i in range(pad_length)]\n",
        "\n",
        "    num = min(len(data), pad_length)\n",
        "    if left:\n",
        "        features[:num] = data[:num]\n",
        "    else:\n",
        "        features[len(features)-num:] = data[:num]\n",
        "    return features\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohS-WnXcaRF5",
        "colab_type": "code",
        "outputId": "189ce008-1964-4d0d-fc5a-8c788ced4857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# encode lyrics\n",
        "pad_length = 100\n",
        "train_sample['lyrics'] = [pad_features(words, pad_length) for words in train_sample['lyrics']]\n",
        "val_sample['lyrics'] = [pad_features(words, pad_length) for words in val_sample['lyrics']]\n",
        "test_sample['lyrics'] = [pad_features(words, pad_length) for words in test_sample['lyrics']]\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esLImofgaZph",
        "colab_type": "code",
        "outputId": "8ef6adf0-da20-454d-beb5-6ff01919fb19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        }
      },
      "source": [
        "train_sample['lyrics'][1]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[920,\n",
              " 86,\n",
              " 2059,\n",
              " 75,\n",
              " 1445,\n",
              " 45,\n",
              " 415,\n",
              " 64,\n",
              " 41011,\n",
              " 337,\n",
              " 549,\n",
              " 559,\n",
              " 27,\n",
              " 15,\n",
              " 988,\n",
              " 18,\n",
              " 7,\n",
              " 340,\n",
              " 781,\n",
              " 33,\n",
              " 21,\n",
              " 457,\n",
              " 1551,\n",
              " 80,\n",
              " 76,\n",
              " 428,\n",
              " 520,\n",
              " 1373,\n",
              " 1373,\n",
              " 103,\n",
              " 19,\n",
              " 80,\n",
              " 76,\n",
              " 332,\n",
              " 570,\n",
              " 570,\n",
              " 260,\n",
              " 465,\n",
              " 260,\n",
              " 465,\n",
              " 260,\n",
              " 465,\n",
              " 12,\n",
              " 181,\n",
              " 515,\n",
              " 1574,\n",
              " 71,\n",
              " 437,\n",
              " 15,\n",
              " 2,\n",
              " 740,\n",
              " 2952,\n",
              " 1320,\n",
              " 4040,\n",
              " 8914,\n",
              " 21,\n",
              " 383,\n",
              " 15,\n",
              " 988,\n",
              " 18,\n",
              " 7,\n",
              " 340,\n",
              " 781,\n",
              " 33,\n",
              " 21,\n",
              " 457,\n",
              " 1551,\n",
              " 80,\n",
              " 76,\n",
              " 428,\n",
              " 520,\n",
              " 1373,\n",
              " 1373,\n",
              " 103,\n",
              " 19,\n",
              " 80,\n",
              " 76,\n",
              " 332,\n",
              " 570,\n",
              " 570,\n",
              " 260,\n",
              " 465,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQcq1gDQbxX8",
        "colab_type": "text"
      },
      "source": [
        "## Convert to pytorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ8-Tq4Zbnau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_data = TensorDataset(torch.tensor(train_sample['lyrics']),\n",
        "                           torch.tensor(train_sample['genre']))\n",
        "\n",
        "val_data = TensorDataset(torch.tensor(val_sample['lyrics']),\n",
        "                           torch.tensor(val_sample['genre']))\n",
        "\n",
        "test_data = TensorDataset(torch.tensor(test_sample['lyrics']),\n",
        "                           torch.tensor(test_sample['genre']))\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "valid_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size, drop_last=True) \n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96DOMgzqdG-_",
        "colab_type": "code",
        "outputId": "6e529da5-cac9-44a2-95b3-8c8f4a1a937d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "# obtain one batch of training data \n",
        "dataiter = iter(train_loader) \n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('Sample input size: ', sample_x.size())\n",
        "print('Sample input: \\n', sample_x) \n",
        "print() \n",
        "print('Sample label size: ', sample_y.size()) # batch_size \n",
        "print('Sample label: \\n', sample_y)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample input size:  torch.Size([50, 100])\n",
            "Sample input: \n",
            " tensor([[11501,  3620,  2603,  ...,  3497,   132,  6529],\n",
            "        [  782,   445,   480,  ...,     0,     0,     0],\n",
            "        [  646,    43,  1171,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [ 4855,   572,  1284,  ...,     0,     0,     0],\n",
            "        [  723,     0,     0,  ...,     0,     0,     0],\n",
            "        [ 2071,   397,   174,  ...,     0,     0,     0]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([ 4, 11,  7,  7,  8,  1,  1,  8,  7,  0,  4,  2,  4,  2,  9, 11,  7,  7,\n",
            "         4,  8,  2,  9, 10,  7,  4, 11, 10,  8,  7,  9, 10,  1,  4,  0,  1, 10,\n",
            "        11,  1, 10,  8,  7,  1,  4,  0, 11, 11, 10,  6,  1, 11])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni0mP-U8eE8v",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-aFioHFUz-2",
        "colab_type": "code",
        "outputId": "96f23643-0540-4216-843d-bcb3973071aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(token_to_int)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41012"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL9PAw1-K3hT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# config.py\n",
        "\n",
        "class Config(object):\n",
        "    embed_size = 300\n",
        "    hidden_layers = 2\n",
        "    hidden_size = 256\n",
        "    bidirectional = True\n",
        "    output_size = 12\n",
        "    max_epochs = 30\n",
        "    lr = 0.1\n",
        "    batch_size = 50\n",
        "    max_sen_len = 100 # Sequence length for RNN\n",
        "    dropout_keep = 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM9X5Fn2RmB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_model(model, iterator):\n",
        "    all_preds = []\n",
        "    all_y = []\n",
        "    for idx,batch in enumerate(iterator):\n",
        "        if torch.cuda.is_available():\n",
        "            x = batch[0].cuda()\n",
        "        else:\n",
        "            x = batch[0]\n",
        "        y_pred = model(x)\n",
        "        predicted = torch.max(y_pred.cpu().data, 1)[1] + 1\n",
        "        all_preds.extend(predicted.numpy())\n",
        "        all_y.extend(batch[1].numpy())\n",
        "    score = accuracy_score(all_y, np.array(all_preds).flatten())\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0-xL5VIJ8D7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.py\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "class TextRNN(nn.Module):\n",
        "    def __init__(self, config, vocab_size, word_embeddings):\n",
        "        super(TextRNN, self).__init__()\n",
        "        self.config = config\n",
        "        \n",
        "        # Embedding Layer\n",
        "        self.embeddings = nn.Embedding(vocab_size, self.config.embed_size)\n",
        "        self.embeddings.weight = nn.Parameter(word_embeddings, requires_grad=False)\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_size = self.config.embed_size,\n",
        "                            hidden_size = self.config.hidden_size,\n",
        "                            num_layers = self.config.hidden_layers,\n",
        "                            dropout = self.config.dropout_keep,\n",
        "                            batch_first=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(self.config.dropout_keep)\n",
        "        \n",
        "       \n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(self.config.hidden_size, 12)\n",
        "        #self.sig = nn.Softmax(dim=1)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embeddings(x)\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        lstm_out, hidden = self.lstm(embeds)\n",
        "\n",
        "        #print('final_cell_state lstm_out shape', lstm_out.shape)\n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out[:, -1,:].squeeze()\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.config.hidden_size)\n",
        "        #print('lstm_out', lstm_out.shape)\n",
        "        #print('hidden', hidden)\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        #sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        #sig_out = sig_out.view(batch_size, -1)\n",
        "        #sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return out    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        hidden = torch.zeros(batch_size,self.config.hidden_layers, self.config.hidden_size)\n",
        "        return hidden\n",
        "    \n",
        "    def add_optimizer(self, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "    def add_loss_op(self, loss_op):\n",
        "        self.loss_op = loss_op\n",
        "    \n",
        "    def reduce_lr(self):\n",
        "        print(\"Reducing LR\")\n",
        "        for g in self.optimizer.param_groups:\n",
        "            g['lr'] = g['lr'] / 2\n",
        "                \n",
        "    def run_epoch(self, train_iterator, val_iterator, epoch):\n",
        "        train_losses = []\n",
        "        val_accuracies = []\n",
        "        losses = []\n",
        "        \n",
        "        # Reduce learning rate as number of epochs increase\n",
        "        if (epoch == int(self.config.max_epochs/3)) or (epoch == int(2*self.config.max_epochs/3)):\n",
        "            self.reduce_lr()\n",
        "            \n",
        "        for i, batch in enumerate(train_iterator):\n",
        "            self.optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "                x = batch[0].cuda()\n",
        "                y = batch[1].type(torch.cuda.LongTensor)\n",
        "            else:\n",
        "                x = batch[0]\n",
        "                y = batch[1].type(torch.LongTensor)\n",
        "\n",
        "            y_pred = self.__call__(x)\n",
        "\n",
        "            loss = self.loss_op(y_pred, y)\n",
        "            loss.backward()\n",
        "            losses.append(loss.data.cpu().numpy())\n",
        "            self.optimizer.step()\n",
        "    \n",
        "            if i % 1500 == 0:\n",
        "                print(\"Iter: {}\".format(i+1))\n",
        "                avg_train_loss = np.mean(losses)\n",
        "                train_losses.append(avg_train_loss)\n",
        "                print(\"\\tAverage training loss: {:.5f}\".format(avg_train_loss))\n",
        "                losses = []\n",
        "                \n",
        "                # Evalute Accuracy on validation set\n",
        "                val_accuracy = evaluate_model(self, val_iterator)\n",
        "                print(\"\\tVal Accuracy: {:.4f}\".format(val_accuracy))\n",
        "                self.train()\n",
        "                \n",
        "        return train_losses, val_accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7xhnamWUnhi",
        "colab_type": "code",
        "outputId": "3fa08f21-8f09-4fef-ff6b-9b4f9b7e20d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "res = fill_with_gloves(token_to_int, path='./glove.6B.300d.txt', emb_size=300, vocab_size='6B', wordvecs=None)\n",
        "res.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n words not found in glove word vectors: 12296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41012, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXhsu6ggKS2D",
        "colab_type": "code",
        "outputId": "566989c3-92bc-48b0-f950-a07da3e6c269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "# train.py\n",
        "\n",
        "import sys\n",
        "import torch.optim as optim\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "if __name__=='__main__':\n",
        "    \n",
        "    config = Config()\n",
        "    # Create Model with specified optimizer and loss function\n",
        "    ##############################################################\n",
        "    model = TextRNN(config, len(token_to_int), torch.from_numpy(res))\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
        "    NLLLoss = torch.nn.CrossEntropyLoss()\n",
        "    model.add_optimizer(optimizer)\n",
        "    model.add_loss_op(NLLLoss)\n",
        "    ##############################################################\n",
        "    \n",
        "    train_losses = []\n",
        "    val_accuracies = []\n",
        "    \n",
        "    for i in range(config.max_epochs):\n",
        "        print (\"Epoch: {}\".format(i))\n",
        "        train_loss,val_accuracy = model.run_epoch(train_loader, valid_loader, i)\n",
        "        train_losses.append(train_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "    train_acc = evaluate_model(model, train_loader)\n",
        "    val_acc = evaluate_model(model, valid_loader)\n",
        "    test_acc = evaluate_model(model, test_loader)\n",
        "\n",
        "    print ('Final Training Accuracy: {:.4f}'.format(train_acc))\n",
        "    print ('Final Validation Accuracy: {:.4f}'.format(val_acc))\n",
        "    print ('Final Test Accuracy: {:.4f}'.format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Iter: 1\n",
            "\tAverage training loss: 2.48149\n",
            "\tVal Accuracy: 0.0194\n",
            "Iter: 1501\n",
            "\tAverage training loss: 3.92200\n",
            "\tVal Accuracy: 0.0272\n",
            "Iter: 3001\n",
            "\tAverage training loss: 3.58911\n",
            "\tVal Accuracy: 0.0464\n",
            "Epoch: 1\n",
            "Iter: 1\n",
            "\tAverage training loss: 3.88360\n",
            "\tVal Accuracy: 0.0474\n",
            "Iter: 1501\n",
            "\tAverage training loss: 3.81020\n",
            "\tVal Accuracy: 0.0613\n",
            "Iter: 3001\n",
            "\tAverage training loss: 3.57414\n",
            "\tVal Accuracy: 0.0313\n",
            "Epoch: 2\n",
            "Iter: 1\n",
            "\tAverage training loss: 3.11340\n",
            "\tVal Accuracy: 0.0354\n",
            "Iter: 1501\n",
            "\tAverage training loss: 3.46352\n",
            "\tVal Accuracy: 0.0260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNAlI1075HLd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d4aa609-4e9a-4ed5-ee1a-64d9d7dcdf01"
      },
      "source": [
        "    train_acc = evaluate_model(model, train_loader)\n",
        "    #val_acc = evaluate_model(model, valid_loader)\n",
        "    #test_acc = evaluate_model(model, test_loader)\n",
        "\n",
        "    print ('Final Training Accuracy: {:.4f}'.format(train_acc))\n",
        "    #print ('Final Validation Accuracy: {:.4f}'.format(val_acc))\n",
        "    #print ('Final Test Accuracy: {:.4f}'.format(test_acc))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Training Accuracy: 0.0531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVHXlEUVfA_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class SentimentLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers,weights, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.embedding.weight = nn.Parameter(weights, requires_grad=False) # Assigning the look-up table to the pre-trained GloVe word embedding.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        #self.sig = nn.Softmax(dim=1)\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        #print('final_cell_state lstm_out shape', lstm_out.shape)\n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out[:, -1,:].squeeze()\n",
        "        #print('lstm_out', lstm_out.shape)\n",
        "        #print('hidden', hidden)\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        #sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        #sig_out = sig_out.view(batch_size, -1)\n",
        "        #sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17e8lfxCf9QM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = fill_with_gloves(token_to_int, path='./glove.6B.300d.txt', emb_size=300, vocab_size='6B', wordvecs=None)\n",
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(token_to_int)+1 # +1 for the 0 padding\n",
        "output_size = len(label_to_int)\n",
        "embedding_dim = 300\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers,torch.from_numpy(res))\n",
        "print(net)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiSTrZubfZLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "train_on_gpu = False\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "# training params\n",
        "\n",
        "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 30\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "\n",
        "\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "    # batch loop\n",
        "    print('hello world----------------------------------------------------')\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # initialize hidden state\n",
        "        #print(inputs.shape)\n",
        "        \n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        inputs = inputs.type(torch.LongTensor)\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        print('shapes-----------------',output.shape, labels.shape)\n",
        "        #print(output)\n",
        "        loss = criterion(output, labels)\n",
        "        print(loss)\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "\n",
        "            val_h = net.init_hidden(inputs.shape[0])\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                \n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                inputs = inputs.type(torch.LongTensor)\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output, labels)\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxFQOS1FTo-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXaXVtPLrbEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "loss = criterion([0.5,0.5],[1,0.5])\n",
        "loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjdXfpMf9DvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "\tdef __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
        "\t\tsuper(LSTMClassifier, self).__init__()\n",
        "\t\t\n",
        "\t\t\"\"\"\n",
        "\t\tArguments\n",
        "\t\t---------\n",
        "\t\tbatch_size : Size of the batch which is same as the batch_size of the data returned by the TorchText BucketIterator\n",
        "\t\toutput_size : 2 = (pos, neg)\n",
        "\t\thidden_sie : Size of the hidden_state of the LSTM\n",
        "\t\tvocab_size : Size of the vocabulary containing unique words\n",
        "\t\tembedding_length : Embeddding dimension of GloVe word embeddings\n",
        "\t\tweights : Pre-trained GloVe word_embeddings which we will use to create our word_embedding look-up table \n",
        "\t\t\n",
        "\t\t\"\"\"\n",
        "\t\t\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.output_size = output_size\n",
        "\t\tself.hidden_size = hidden_size\n",
        "\t\tself.vocab_size = vocab_size\n",
        "\t\tself.embedding_length = embedding_length\n",
        "\t\t\n",
        "\t\tself.word_embeddings = nn.Embedding(vocab_size, embedding_length)# Initializing the look-up table.\n",
        "\t\tself.word_embeddings.weight = nn.Parameter(weights, requires_grad=False) # Assigning the look-up table to the pre-trained GloVe word embedding.\n",
        "\t\tself.lstm = nn.LSTM(embedding_length, hidden_size)\n",
        "\t\tself.label = nn.Linear(hidden_size, output_size)\n",
        "\t\t\n",
        "\tdef forward(self, input_sentence, batch_size=None):\n",
        "\t\n",
        "\t\t\"\"\" \n",
        "\t\tParameters\n",
        "\t\t----------\n",
        "\t\tinput_sentence: input_sentence of shape = (batch_size, num_sequences)\n",
        "\t\tbatch_size : default = None. Used only for prediction on a single sentence after training (batch_size = 1)\n",
        "\t\t\n",
        "\t\tReturns\n",
        "\t\t-------\n",
        "\t\tOutput of the linear layer containing logits for positive & negative class which receives its input as the final_hidden_state of the LSTM\n",
        "\t\tfinal_output.shape = (batch_size, output_size)\n",
        "\t\t\n",
        "\t\t\"\"\"\n",
        "\t\t\n",
        "\t\t''' Here we will map all the indexes present in the input sequence to the corresponding word vector using our pre-trained word_embedddins.'''\n",
        "\t\tinput = self.word_embeddings(input_sentence) # embedded input of shape = (batch_size, num_sequences,  embedding_length)\n",
        "\t\tinput = input.permute(1, 0, 2) # input.size() = (num_sequences, batch_size, embedding_length)\n",
        "\t\tif batch_size is None:\n",
        "\t\t\th_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()) # Initial hidden state of the LSTM\n",
        "\t\t\tc_0 = Variable(torch.zeros(1, self.batch_size, self.hidden_size).cuda()) # Initial cell state of the LSTM\n",
        "\t\telse:\n",
        "\t\t\th_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
        "\t\t\tc_0 = Variable(torch.zeros(1, batch_size, self.hidden_size).cuda())\n",
        "\t\toutput, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0))\n",
        "\t\tfinal_output = self.label(final_hidden_state[-1]) # final_hidden_state.size() = (1, batch_size, hidden_size) & final_output.size() = (batch_size, output_size)\n",
        "\t\t\n",
        "\t\treturn final_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZXGIZp8eI2o",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}